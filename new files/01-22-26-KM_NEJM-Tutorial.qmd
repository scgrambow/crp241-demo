---
title: "Simulating Clinical Trials: The Kaplan-Meier Method"
subtitle: "CRP 245 Advanced Tutorial — CheckMate 816 Case Study"
author: "Duke University Clinical Research Training Program"
date: today
format:
  html:
    toc: true
    toc-depth: 3
    toc-location: left
    code-fold: false
    code-tools: true
    code-line-numbers: true
    theme: cosmo
    embed-resources: true
    number-sections: true
  pdf:
    toc: true
    number-sections: true
    colorlinks: true
    engine: xelatex
execute:
  warning: false
  message: false
  echo: true
---

# Introduction {.unnumbered}

::: {.callout-note icon=false}
## Learning Objectives

After completing this tutorial, you will be able to:

- **Simulate** survival data calibrated to published trial results.
- **Distinguish** between the event process and the censoring process in survival analysis.
- **Explain** why risk tables diverge between simulated and real trial data.
- **Interpret** hazard ratios and their dependence on reference group coding.
- **Generate** publication-quality Kaplan-Meier plots with confidence intervals and risk tables.
- **Connect** statistical code to the biological and operational realities of clinical trials.
:::

## Why Simulate a Published Trial?

Simulation is a powerful pedagogical tool. By reconstructing a landmark trial's survival curves from first principles, you develop intuition for how the Kaplan-Meier estimator behaves under different assumptions about event rates, censoring patterns, and sample sizes.

In this tutorial, we simulate data matching the **CheckMate 816 trial** (Forde et al., *NEJM* 2025;393:741-752), which demonstrated that neoadjuvant nivolumab plus chemotherapy significantly improved overall survival in resectable non–small-cell lung cancer compared to chemotherapy alone.

::: {.callout-tip}
## The Two Processes in Survival Data

Every survival dataset is shaped by two distinct stochastic processes:
 
1. **The Event Process**: When do patients die (or experience the outcome)? This is what we care about clinically.

2. **The Censoring Process**: When do we lose track of patients who haven't yet had the event? This is driven by study logistics—enrollment timing, administrative end dates, loss to follow-up.

The Kaplan-Meier estimator extracts information about the event process while accounting for the censoring process. Understanding both is essential for correct interpretation.
:::

## Source Trial: CheckMate 816

| Parameter | Value |
|:----------|:------|
| **Design** | Phase 3, open-label, randomized |
| **Population** | Stage IB–IIIA resectable NSCLC |
| **Arms** | Nivolumab + platinum-based chemotherapy vs. chemotherapy alone |
| **N per arm** | 179 |
| **Primary endpoints** | Pathological complete response, event-free survival |
| **Key secondary endpoint** | Overall survival |
| **Median follow-up** | 68.4 months |
| **5-year OS (Nivo+Chemo)** | 65.4% (95% CI: 57.8–71.9) |
| **5-year OS (Chemo)** | 55.0% (95% CI: 47.3–62.0) |
| **HR for death** | 0.72 (95% CI: 0.523–0.998; P=0.048) |
| **Deaths** | 66 (Nivo+Chemo) vs. 84 (Chemo) |

: CheckMate 816 Key Results {.striped .hover}

---

# Setup and Package Loading

```{r setup}
# Install packages if needed
if (!requireNamespace("survival", quietly = TRUE)) install.packages("survival")
if (!requireNamespace("survminer", quietly = TRUE)) install.packages("survminer")
if (!requireNamespace("dplyr", quietly = TRUE)) install.packages("dplyr")

library(survival)
library(survminer)
library(dplyr)
```

---

# The Simulation Strategy

## Calibrating to Published Results

We don't have access to the individual patient data from CheckMate 816, but we can reverse-engineer plausible survival times by calibrating a parametric distribution to the reported 5-year survival percentages.

::: {.callout-note}
## Why Weibull, Not Exponential?

The **exponential distribution** assumes a constant hazard over time—the risk of death at month 60 is the same as at month 6. This is biologically implausible for most cancers, where hazard typically increases as disease progresses.
 
The **Weibull distribution** generalizes the exponential by adding a shape parameter ($k$):
 
$$S(t) = \exp\left[-\left(\frac{t}{\lambda}\right)^k\right]$$
 
- $k = 1$: Constant hazard (exponential)
- $k > 1$: Increasing hazard over time (common in oncology)
- $k < 1$: Decreasing hazard (e.g., post-surgical mortality risk)

For this simulation, we use $k = 1.2$, reflecting modestly increasing hazard—consistent with advanced lung cancer biology.
:::

## The Calibration Math

Given a target survival probability $S^*$ at time $t^*$, we solve for the scale parameter $\lambda$:

$$S(t^*) = S^* \implies \lambda = \frac{t^*}{\left[-\ln(S^*)\right]^{1/k}}$$

For the chemotherapy arm with 55% 5-year survival:

$$\lambda_{\text{chemo}} = \frac{60}{\left[-\ln(0.55)\right]^{1/1.2}} \approx 100.4 \text{ months}$$

```{r calibration}
# Shape parameter (k > 1 = increasing hazard)
k_shape <- 1.2

# Calibrate scale parameters to match 5-year survival
lambda_chemo <- 60 / (-log(0.55))^(1/k_shape)
lambda_nivo  <- 60 / (-log(0.654))^(1/k_shape)

cat("Scale parameter (Chemo):", round(lambda_chemo, 1), "months\n")
cat("Scale parameter (Nivo+Chemo):", round(lambda_nivo, 1), "months\n")
```

---

# Generating Simulated Data

## The Event Process

We generate survival times for each arm using the calibrated Weibull distributions.

```{r event-process}
set.seed(816)  # Mnemonic: CheckMate 816

n_per_group <- 179

# Generate "true" survival times (what would happen without censoring)
time_chemo <- rweibull(n_per_group, shape = k_shape, scale = lambda_chemo)
time_nivo  <- rweibull(n_per_group, shape = k_shape, scale = lambda_nivo)
```

## The Censoring Process

::: {.callout-important}
## Critical Concept: Why Censoring Patterns Matter

In a real trial like CheckMate 816:

- **Enrollment was staggered** over 32 months (March 2017–November 2019).
- **Database lock** occurred January 2025.
- A patient enrolled in March 2017 could have up to 94 months of follow-up.
- A patient enrolled in November 2019 could have at most 62 months of follow-up.

This creates **heterogeneous censoring**: patients enrolled late are administratively censored earlier, even if they're still alive. The risk table collapses toward the tail because many patients simply haven't been followed long enough—not because they died or dropped out.

**Our simulation simplifies this** by using uniform random censoring times between 60–85 months. This captures the general idea of variable follow-up but doesn't replicate the specific enrollment curve. As a result, our simulated risk table retains more patients at later timepoints than the real trial.
:::

```{r censoring-process}
# Simulate censoring times (administrative end of follow-up)
# Uniform distribution approximates staggered enrollment + fixed analysis date
censor_chemo <- runif(n_per_group, min = 60, max = 85)
censor_nivo  <- runif(n_per_group, min = 60, max = 85)

# What we actually observe: the earlier of death or censoring
obs_time_chemo <- pmin(time_chemo, censor_chemo)
obs_time_nivo  <- pmin(time_nivo, censor_nivo)

# Event indicator: 1 = death observed, 0 = censored
status_chemo <- as.integer(time_chemo <= censor_chemo)
status_nivo  <- as.integer(time_nivo <= censor_nivo)
```

## Assembling the Dataset

```{r assemble-data}
# Create analysis dataset
# IMPORTANT: Set Chemotherapy as the reference level for correct HR orientation
checkmate_sim <- data.frame(
  time   = c(obs_time_chemo, obs_time_nivo),
  status = c(status_chemo, status_nivo),
  group  = factor(
    rep(c("Chemotherapy Alone", "Nivolumab + Chemotherapy"), each = n_per_group),
    levels = c("Chemotherapy Alone", "Nivolumab + Chemotherapy")
  )
)

# Preview the data structure
head(checkmate_sim)
str(checkmate_sim)
```

::: {.callout-warning}
## The Reference Group Trap

In R, the first level of a factor becomes the reference category in regression models. The hazard ratio from `coxph()` compares the second level *to* the first level.
 
If you set `levels = c("Nivolumab + Chemotherapy", "Chemotherapy Alone")`, the HR will compare Chemo to Nivo—and you'll get HR ≈ 1.35 instead of 0.72. These are reciprocals describing the same survival difference, but the clinical convention is to report the experimental arm vs. control.
 
**Always verify your factor ordering before interpreting hazard ratios.**
:::

---

# Kaplan-Meier Analysis

## Fitting the Model

```{r km-fit}
# Fit Kaplan-Meier survival curves by treatment group
km_fit <- survfit(Surv(time, status) ~ group, data = checkmate_sim)

# Summary at key timepoints
summary(km_fit, times = c(12, 24, 36, 48, 60))
```

## Cox Proportional Hazards Model

```{r cox-model}
# Fit Cox model for hazard ratio
cox_fit <- coxph(Surv(time, status) ~ group, data = checkmate_sim)

# Extract HR and confidence interval
hr_estimate <- exp(coef(cox_fit))
hr_ci <- exp(confint(cox_fit))

cat("Hazard Ratio:", round(hr_estimate, 2), "\n")
cat("95% CI:", round(hr_ci[1], 2), "–", round(hr_ci[2], 2), "\n")
```

::: {.callout-note}
## Interpreting the Hazard Ratio

A hazard ratio of 0.74 means that at any given moment during follow-up, patients receiving nivolumab plus chemotherapy have approximately 26% lower instantaneous risk of death compared to those receiving chemotherapy alone.
 
**Key assumptions:**
 
- The HR is constant over time (proportional hazards assumption).
- The comparison is adjusted for the censoring mechanism.
- The confidence interval crossing 1.0 would indicate non-significance; here, the upper bound is close to but below 1.0.
:::

---

# Publication-Quality Visualization

```{r km-plot}
#| label: fig-km-main
#| fig-cap: "Simulated CheckMate 816: Kaplan-Meier Estimates of Overall Survival"
#| fig-height: 7
#| fig-width: 9

km_plot <- ggsurvplot(
  km_fit,
  data = checkmate_sim,
  
  # Risk table
  risk.table = TRUE,
  risk.table.col = "strata",
  risk.table.height = 0.25,
  risk.table.y.text = FALSE,
  tables.theme = theme_cleantable(),
  
  # Aesthetics
  palette = c("#A23B72", "#2E86AB"),
  linetype = "solid",
  size = 1.2,
  
  # Confidence intervals
  conf.int = TRUE,
  conf.int.alpha = 0.15,
  
  # Censoring marks
  censor = TRUE,
  censor.shape = "|",
  censor.size = 3,
  
  # Axis formatting
  xlim = c(0, 84),
  break.time.by = 12,
  xlab = "Months Since Randomization",
  ylab = "Overall Survival (%)",
  surv.scale = "percent",
  
  # Legend
  legend = c(0.75, 0.25),
  legend.title = "",
  legend.labs = c("Chemotherapy Alone", "Nivolumab + Chemotherapy"),
  
  # P-value
  pval = TRUE,
  pval.coord = c(5, 0.15),
  
  # Title
  title = "Simulated CheckMate 816: Overall Survival",
  font.title = c(14, "bold"),
  
  # Theme
  ggtheme = theme_classic2(base_size = 12)
)

# Add HR annotation
km_plot$plot <- km_plot$plot +
  ggplot2::annotate(
    "text", x = 5, y = 0.22,
    label = sprintf("HR = %.2f (95%% CI: %.2f–%.2f)",
                    hr_estimate, hr_ci[1], hr_ci[2]),
    hjust = 0, size = 3.5
  )

print(km_plot)
```

---

# Simulation Diagnostics

## Comparing Simulated vs. Target Statistics

```{r diagnostics}
# Event counts
cat("=== Event Counts ===\n")
cat(sprintf("Nivo+Chemo: %d events (target: ~66)\n", sum(status_nivo)))
cat(sprintf("Chemo:      %d events (target: ~84)\n", sum(status_chemo)))

# 5-year survival
surv_summary <- summary(km_fit, times = 60)
cat("\n=== 5-Year Overall Survival ===\n")
cat(sprintf("Chemo:      %.1f%% (target: 55.0%%)\n", surv_summary$surv[1] * 100))
cat(sprintf("Nivo+Chemo: %.1f%% (target: 65.4%%)\n", surv_summary$surv[2] * 100))

# Hazard ratio
cat("\n=== Hazard Ratio ===\n")
cat(sprintf("Simulated: %.2f (target: 0.72)\n", hr_estimate))
```

::: {.callout-important}
## Why the Risk Tables Differ

Comparing our simulation to the published CheckMate 816 figure:

| Timepoint | Real Trial (Nivo / Chemo) | Simulation (Nivo / Chemo) |
|:----------|:--------------------------|:--------------------------|
| 0 months  | 179 / 179 | 179 / 179 |
| 60 months | 67 / 58 | ~110 / ~95 |
| 72 months | 29 / 29 | ~65 / ~50 |

The survival *estimates* match well because our Weibull parameters correctly model the event process. But the risk tables diverge because our censoring process (uniform 60–85 months) differs from the real trial's staggered enrollment pattern.
 
**In the real trial:** Many patients enrolled in 2018–2019 hadn't reached 72 months of follow-up by the January 2025 data lock. They were censored early—not because they died or dropped out, but because the calendar ran out.
 
**In our simulation:** Censoring is spread uniformly across 60–85 months, so more patients remain "at risk" at the 72-month mark.
 
This is a crucial teaching point: **censoring is non-informative for the survival estimate but fundamentally shapes what we observe in the risk table.**
:::

---
 
# Extension: Modeling Realistic Enrollment

To better match the real trial's risk table, you could simulate the actual enrollment process:

```{r enrollment-extension}
#| eval: false

# More realistic censoring: simulate staggered enrollment
# Enrollment period: 32 months (uniform)
# Analysis date: 94 months after first enrollment
enrollment_time <- runif(n_per_group, min = 0, max = 32)
analysis_date <- 94  # months from first patient enrolled

# Maximum possible follow-up for each patient
max_followup <- analysis_date - enrollment_time

# Censoring occurs at max follow-up (or earlier if loss to follow-up)
censor_time_realistic <- pmin(max_followup, rexp(n_per_group, rate = 0.005))
```

This refinement would collapse the risk table more dramatically toward the tail, matching the real figure more closely.

---

# Practice Checkpoint {.unnumbered}

::: {.callout-important}
## Key Teaching Points

- [ ] **Two processes**: Event times and censoring times are generated independently in simulation.
- [ ] **Weibull calibration**: Solve for scale parameter given target survival probability.
- [ ] **Factor levels**: The reference group determines HR direction—always check.
- [ ] **Risk table interpretation**: Reflects censoring pattern, not just deaths.
- [ ] **Simulation utility**: Lets you explore "what if" scenarios impossible in real data.
:::

## Discussion Questions

1. **What would happen to the HR if we used a higher shape parameter (k = 1.5)?** Would the curves separate earlier or later?

2. **If the real trial had 50% loss to follow-up, how would that affect the 5-year survival estimate?** Would it be biased? In which direction?

3. **The CheckMate 816 HR confidence interval is (0.523, 0.998). Why is this clinically important?** What does the upper bound approaching 1.0 tell us?

---

# References {.unnumbered}

- Forde PM, Spicer JD, Provencio M, et al. Overall Survival with Neoadjuvant Nivolumab plus Chemotherapy in Lung Cancer. *N Engl J Med* 2025;393:741-752. DOI: 10.1056/NEJMoa2502931

- Kaplan EL, Meier P. Nonparametric estimation from incomplete observations. *J Am Stat Assoc* 1958;53:457-481.

- Collett D. *Modelling Survival Data in Medical Research*. 3rd ed. CRC Press; 2015.

---

*This tutorial was developed for CRP 245 at Duke University Clinical Research Training Program.*